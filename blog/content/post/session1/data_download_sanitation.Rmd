---
title: "Data Download and Sanitation (and our first plot!)"
author: "Zach"
date: "2020-03-30"
output: html_document
---


```{r include=FALSE}
knitr::opts_chunk$set(message=FALSE)
knitr::opts_chunk$set(warning = FALSE)
```

# March 30, 2020
Hello, and welcome to a summary of the first training session for bio-group technical
development!  This is an Rmarkdown document that will walk you through what we 
did in the first session on March 30, 2020.  Here we will download the data from the
[*JHU CSSE database*](https://github.com/CSSEGISandData/COVID-19) and plot the
reported confirmed cases, deaths, and recoveries for a country of interest
since January 22, 2020.


## Libraries
At the top of any script we write, first we include all the libraries used in this
analysis.   These "libraries" are packages of code that we import to our script 
so we may use some of their handy features.  For example, the `xml2` library allows
us to download a webpage and extract all of the text from it in just a few simple
lines of code!  A few commonly used libraries include `data.table`, `dplyr`, and 
`magrittr`, all of which we will go into later.
```{r libraries}
library(magrittr)
library(xml2)
library(lubridate)
library(data.table)
library(dplyr)
library(ggplot2)
```


## Set paths
This line is purely procedural.  Here we tell R in a platform-agnostic way where 
to put on your computer the downloaded csv data as well as the R scripts.  In 
other words, R makes a guess at where your home directory is, regardless of whether
you are using Windows, MacOS, or Linux.
```{r set-paths}
git.path <- Sys.getenv('HOME')  # Where the base COVID19-Data-Exploration folder lives.
```


## Fetching the CSV data from Github and importing it to the database
Here's where we start to get our hands dirty.  In the 3 code chunks below, we 
first download the Github webpage that has all of the csv files in it and extract 
the text  Second, we look through all of that text for any
string of characters in the date format MM-DD-YYYY (since that is the naming 
convention for all of the csv files) and make a list of those dates.  
Finally, we use the list of dates (corresponding to the names of the csv files)
to download the any new data into the PostgreSQL database hosted by Kyle.

```{r scrape-webpage}
# Pull in list of daily data. 
xml.path <- 'https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports'
report.file <- download_html(xml.path)
html.read <- read_html(report.file)
csv.list <- xml_text(html.read) %>% strsplit(split='\\n') %>% unlist
```

```{r parse-dates}
dates.list <- lapply(csv.list, function(x) {
    if (grepl(pattern='.csv', x, fixed=TRUE)) {
        regex <- regexpr('\\d{2}-\\d{2}-\\d{4}.csv', x)
        return(substr(x, start=regex[[1]], stop=regex[[1]]+attr(regex, 'match.length')))
    }
}) 
dates.list[sapply(dates.list, is.null)] <- NULL
dates.list <- dates.list %>% tstrsplit(split='.csv', keep=1) %>% unlist
```

```{r fetch-data}
# Get list of dates we do have
source(file.path(git.path, 'Code/config_files/db_config.R'))
con <- db_connect.fn()
curr_dates.list <- dbGetQuery(con, 'SELECT last_update FROM covid_data.report_data') %>%
     group_by(last_update) %>% summarize
dbDisconnect(con)

# Force dates to be in mm/dd/yyyy to comply with JHU CSSE date formatting.  This code
# makes me very sad :(
curr_dates.list$last_update <- curr_dates.list$last_update %>% year %>% 
    paste0(curr_dates.list$last_update,'-',.) %>% sub('\\d{4}-',"",.)

# Insert data for dates we don't have into database
missing_dates <- dates.list[!(dates.list %in% curr_dates.list$last_update)]
if (length(missing_dates) > 0) {
    source(file.path(git.path, 
                     'Code/COVID19-Data-Exploration/scripts/R/session2/insert_report_data.R'),
           local=T)
    con <- db_connect.fn()
    tryCatch({
        insert_report_data(con, missing_dates)  
    }, 
    error = function(e) {
        print('ERROR: Database not updated!')
        print(e)
    })
    dbDisconnect(con)
} else {
    print('No new data to download!')
}
```


## Querying and Filtering Data
Now that we have filled in the database with the most up-to-date information, let's query 
the some data to work with.  We can do this by simply requesting the data from the 
database using Structured Query Language (SQL) commands.  SQL is the lingua franca of
databases; we will go deeper into this topic in session 2.  

R, as well as many other languages, offer ways to interface with SQL that allow you to use
R idioms to invoke SQL commands.  the `dbGetQuery` function (imported from `RPostgreSQL`) is a command specific to R that allows us to ask the database to send us the data (via a
SQL invocation) and return it to us in a form usable by R.  Here, we ask for the 3 most
recent months of data from the database, and then combine all of the data into one handy
`data.table`.  
```{r query-database}
library(RPostgreSQL)

# Acquire COVID data from database.  Default to most recent 3-month period
con <- db_connect.fn()
end.date <- Sys.Date()
start.date <- end.date - 90  # 90-days ~ 3 months
q1 <- "SELECT * FROM covid_data.report_data"
q2 <- paste0("WHERE last_update >= '", start.date, "'::DATE AND last_update <= '", 
             end.date,"'::DATE")
data.dt <- dbGetQuery(con, paste(q1, q2)) %>% data.table
dbDisconnect(con)

data.dt
```

Finally, after all that work, we have our data downloaded, cleaned, and in a format 
suitable for analysis.  We can begin thinking of questions that we want to
answer using the data.  This is an early step in the exploratory data analysis phase.
A first probing question may be, "For our country of interest, what are the number 
of confirmed cases, reported deaths, and reported recoveries?"

To answer this question, we are going to make a few simple plots to visually see
how the number of confirmed COVID-19 cases, the number of reported deaths due to
the virus, and the number of reported cases have changed over time.

### Replace NA's with zeros
It is often convenient to replace `NA` values in a dataset with zeros, since `NA` 
values in R (as well as other programming languages) can have weird or behavior 
that may be different from what you are expecting (e.g. summing values in
column that has an `NA` in it will return `NA`).
### Select Country
Choose country to look at.  We are using Italy here because it is more easy
to verify our results with those reported by the CSSE data dashboard.
```{r country-switch}
country.switch <- 'US'
```

### Filter by country, group by day, and summarize
This is our first step where we really start to manipulate the data to answer our
question of interest.  All of the organizing we did to our data before this was so
that we can use these powerful filtering, grouping and summarizing tools to select
the chunks of our data that we are interested in. 

These 4 lines make heavy use of `%>%`, which is the piping operator from the 
`magrittr` library.  This conveniently allows us to string together multiple
operations in a single step.  In the 4 lines below we:

1. `SELECT` from the dataset only the rows that match our country of interest.
2. `GROUP` the selected rows by their date (to get a chronological timeline of
   the number of cases in each category).
3. `SUMMARIZE` all the observations (i.e. rows) for each date into a single value.
       The sum of all obeservations for all cases of a particular type will reflect
       the number of reported confirmed cases/deaths/recoveries for that day.
       
```{r filter-group-summarize}
# Summarize country data and plot by case type
country_cases.dt <- data.dt[data.dt$country_region==country.switch,] %>% 
    group_by(last_update) %>% 
    summarize(confirmed=sum(confirmed),
              deaths=sum(deaths), 
              recovered=sum(recovered)) %>% data.table
```


## Our First Plots
Finally, let us plot the data!  Here we make use of the `ggplot2` library to
visualize our data.  We'll split the data by case type (*confirmed*, *deaths*, and
*recovered*) and plot each separately.  For all plots, the y-axis reflects the number of
reported cases for each type, and the x-axis shows the increase over time.

```{r plot-cases}
# Confirmed
melted.dt <- melt(country_cases.dt, id.vars='last_update', variable.name = 'cases', 
                  value.name='number.reported')
ggplot(melted.dt, aes(x=last_update, y=number.reported, color=cases)) +
    geom_point() + 
    geom_line() +
    ggtitle(paste("Total Confirmed Cases in", country.switch))

# Deaths
melted.dt <- melt(country_cases.dt[,c('last_update','deaths')], 
                  id.vars='last_update', variable.name = 'cases', 
                  value.name='number.reported')
ggplot(melted.dt, aes(x=last_update, y=number.reported, color=cases)) +
    geom_point() + 
    geom_line() +
    ggtitle(paste("Total Deaths in", country.switch))

# Recovered
melted.dt <- melt(country_cases.dt[,c('last_update','recovered')], 
                  id.vars='last_update', variable.name = 'cases', 
                  value.name='number.reported')
ggplot(melted.dt, aes(x=last_update, y=number.reported, color=cases)) +
    geom_point() + 
    geom_line() +
    ggtitle(paste("Total Recovered Cases in", country.switch))
```

***

These plots may seem simple, but beneath them lies a wealth of information.  What
questions do you have after viewing them?
    

# Further reading
See the following links for information on the following topics:

* [*Data tables*](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html) in R


* [*R for Data Science*](https://r4ds.had.co.nz/).  An excellent resource for those
who want to delve into other data sets on their own, learning data analysis from 
the ground up in R.  Accessible to all levels of experience!
