---
title: "Bringing It All Together"
author: "Zach"
date: "2020-06-01"
output: html_document
---



<div id="so-whats-it-all-been-about" class="section level2">
<h2>So What’s It All Been About?</h2>
<p>We’ve done a lot over the past 4 training sessions, so let’s review what we’ve done. I’ll briefly summarize what we’ve done, and then will generate for us a tidy little Rmarkdown report in which we can see how far we have come.</p>
</div>
<div id="session-1-data-download-and-sanitization" class="section level2">
<h2><a href="https://bioanalytics-cvo-quantumspatial.netlify.app/2020/03/30/data-download-and-sanitation-and-our-first-plot/">Session 1: Data Download and Sanitization</a></h2>
<p>In the first session, we pulled data from the <a href="https://github.com/CSSEGISandData/COVID-19"><strong>John’s Hopkins database</strong></a> and generated plots of the number of reported cases, deaths, and recoveries for a particular country of interest.</p>
<p><img src="/post/session5/summary_files/figure-html/session-1-1.png" width="672" /></p>
<p>To do this, we had to do a some manipulation of the original data to get them into a format suitable for our purposes. This is a common hallmark of any project with data that is to be analyzed – the initial pipeline down which the data are processed can be just as important as the end product. The main projects in that we work on, CADWR and CalWater, both have automated ingestion pipelines that build out the projects’ folder structures as well as perform quality checks on the data as they come in. These were made possible by Herculean efforts on the parts of Aron, Kelsey, and Kyle!</p>
</div>
<div id="session-2-introduction-to-databases-and-a-simple-gis-example-using-the-sf-library" class="section level2">
<h2><a href="https://bioanalytics-cvo-quantumspatial.netlify.app/2020/04/13/an-introduction-to-databases/">Session 2: Introduction to Databases and a Simple GIS Example using the <code>sf</code> Library</a></h2>
<p>In The second session, Kyle introduced us to the basics of databases by converting the script from the first session to download data directly into</p>
</div>
